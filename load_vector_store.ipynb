{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97a227f-423f-49b3-a837-3d4541c40872",
   "metadata": {},
   "source": [
    "### Oracle AI Vector Search: test Loading the Vector Store\n",
    "* based on the **LangChain** integration\n",
    "* based on **OCI GenAI multi-lingual embeddings**\n",
    "* Data will be stored in a single table (ORACLE_KNOWLEDGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64d9fd0-36d2-43bf-b59c-b25001673ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# to load and split txt documents\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# to compute embeddings vectors\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "# the class to integrate OCI AI Vector Search with LangChain\n",
    "from oracle_vector_db_lc import OracleVectorStore\n",
    "\n",
    "from config_private import COMPARTMENT_OCID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d39f9-d1c4-4c0f-8d1a-a9c7bc9fcbf8",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526385c8-16d1-4c4e-a358-47d246e98a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Helper functions\n",
    "#\n",
    "\n",
    "\n",
    "# find the url from the file name, using references.csv\n",
    "def find_ref(df, f_name):\n",
    "    condition = df[\"file_name\"] == f_name\n",
    "\n",
    "    ref = df.loc[condition][\"url\"].values[0]\n",
    "\n",
    "    return ref\n",
    "\n",
    "\n",
    "def set_url_in_docs(docs, df_ref):\n",
    "    docs = docs.copy()\n",
    "    for doc in docs:\n",
    "        # remove txt from file_name\n",
    "        file_name = doc.metadata[\"source\"]\n",
    "        only_name = file_name.split(\"/\")[-1]\n",
    "        # find the url from the csv\n",
    "        ref = find_ref(df_ref, only_name)\n",
    "\n",
    "        doc.metadata[\"source\"] = ref\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8da1d7c-25b0-4e7d-9d5f-ec6b1529cd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directory where the Knowledge base is contained in txt files\n",
    "TXT_DIR = \"./txt\"\n",
    "# file with f_name,url\n",
    "REF_FILE = \"references.csv\"\n",
    "\n",
    "# OCI GenAI model used for Embeddings\n",
    "EMBED_MODEL = \"cohere.embed-multilingual-v3.0\"\n",
    "ENDPOINT = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "# max length in token of the input for embeddings\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "# max chunk size, in char, for splitting\n",
    "CHUNK_SIZE = 1500\n",
    "# this parameters needs to be adjusted for the Embed model (for example, lowered for Cohere)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef2fd13-0ac8-4a9c-acbf-4a2174bca928",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 75 files to be loaded...\n"
     ]
    }
   ],
   "source": [
    "# this is the file list containing the Knowledge base\n",
    "file_list = sorted(glob(TXT_DIR + \"/\" + \"*.txt\"))\n",
    "\n",
    "print(f\"There are {len(file_list)} files to be loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801e226-e346-4836-b35a-94e15d28e695",
   "metadata": {},
   "source": [
    "#### Load all text files and then splits in chunks\n",
    "Here we do some preprocessing on the txt file:\n",
    "* we replace the file_name in source with the url the txtis coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76563e53-5dfc-45d7-b6a7-87f9a3606398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████████████████████▉ | 75/76 [00:00<00:00, 4345.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have splitted docs in 437 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read all references (url)\n",
    "df_ref = pd.read_csv(REF_FILE)\n",
    "\n",
    "# load txt and splits in chunks\n",
    "# with TextLoader it is fast\n",
    "# documents read not yet splitted\n",
    "origin_docs = DirectoryLoader(\n",
    "    TXT_DIR, glob=\"**/*.txt\", show_progress=True, loader_cls=TextLoader\n",
    ").load()\n",
    "\n",
    "\n",
    "# replace the f_name with the reference (url)\n",
    "origin_docs = set_url_in_docs(origin_docs, df_ref)\n",
    "\n",
    "# split docs in chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # thse params must be adapted to Knowledge base\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "docs_splitted = text_splitter.split_documents(origin_docs)\n",
    "\n",
    "print(f\"We have splitted docs in {len(docs_splitted)} chunks...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a854c-ba3b-4db3-99d0-ce2e4d5ff8db",
   "metadata": {},
   "source": [
    "#### Create Embed Model, Vector Store and load vectors + embeddings in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1eb43ac-1975-4091-a691-f42ce8163ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:50:53,766 - INFO - ORACLE_KNOWLEDGE truncated!!!\n"
     ]
    }
   ],
   "source": [
    "# clean the existing table\n",
    "# be careful: do you really want to delete all the existing records?\n",
    "OracleVectorStore.drop_collection(collection_name=\"ORACLE_KNOWLEDGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6feaa50-d4e8-4f65-9b10-74fc3cc467fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OCIGenAIEmbeddings\n__root__\n  Could not authenticate with OCI client. Please check if ~/.oci/config exists. If INSTANCE_PRINCIPLE or RESOURCE_PRINCIPLE is used, Please check the specified auth_profile and auth_type are valid. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create embedding model and then the vector store\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# create the Embedding Model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m \u001b[43mOCIGenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# this code is done to be run in OCI DS. \u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If outside replace with API_KEYS and provide API_KEYS\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAPI_KEYS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBED_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompartment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOMPARTMENT_OCID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# this one compute embeddings and load texts + embeddings in DB\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# can take minutes (for embeddings)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m v_store \u001b[38;5;241m=\u001b[39m OracleVectorStore\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[1;32m     16\u001b[0m     docs_splitted, embed_model, collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORACLE_KNOWLEDGE\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_env01/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OCIGenAIEmbeddings\n__root__\n  Could not authenticate with OCI client. Please check if ~/.oci/config exists. If INSTANCE_PRINCIPLE or RESOURCE_PRINCIPLE is used, Please check the specified auth_profile and auth_type are valid. (type=value_error)"
     ]
    }
   ],
   "source": [
    "# create embedding model and then the vector store\n",
    "\n",
    "# create the Embedding Model\n",
    "embed_model = OCIGenAIEmbeddings(\n",
    "    # this code is done to be run in OCI DS.\n",
    "    # If outside replace with API_KEY and provide API_KEYS\n",
    "    auth_type=\"API_KEY\",\n",
    "    model_id=EMBED_MODEL,\n",
    "    service_endpoint=ENDPOINT,\n",
    "    compartment_id=COMPARTMENT_OCID,\n",
    ")\n",
    "\n",
    "# this one compute embeddings and load texts + embeddings in DB\n",
    "# can take minutes (for embeddings)\n",
    "v_store = OracleVectorStore.from_documents(\n",
    "    docs_splitted, embed_model, collection_name=\"ORACLE_KNOWLEDGE\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333cb53-74db-4928-9d40-9bf046d6a7f6",
   "metadata": {},
   "source": [
    "#### Do a query for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9553485-4cfa-4da3-89b2-f8431206b3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# k is the number of docs we want to retrieve\n",
    "retriever = v_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e60a8-114f-4377-bcca-aeaa93c2b2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"What is Autonomous Database on OCI\"\n",
    "\n",
    "result_docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960e460-3182-4586-9cec-2e83870ffbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc in result_docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata[\"source\"])\n",
    "    print(\"----------------------------\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f105a80-3cc3-4c2c-8676-163f31a98252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
