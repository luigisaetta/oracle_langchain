The advent of powerful cloud infrastructures combined with advanced GPUs has enabled us to push the boundaries of what’s possible with AI. Over the last year, generative AI models have astounded us with their capabilities. These models are not just passing an extensive qualification exam to become a lawyer, but achieving a score in the 90th percentile. Or writing term papers on topics that range from history to philosophy. Or being used for information discovery, when we once defaulted to search engines.
Now, we’re watching generative AI create text, generate SQL queries, write code, create artwork, and assist in product support—all of which seemed impossible just a few years ago. These feats have captured the imagination of enterprise executives who see immense potential to improve productivity and revenue with generative AI.
What enterprises need is generative AI capabilities and use cases that can impact business outcomes. Generative AI that leverages models that are fine-tuned on—or augmented by—an organization’s data and intellectual property, designed to deliver outputs only a model familiar with the organization can deliver.
Along with the technology, what enterprises need is a partner that can be relied on to meet multiple needs—from configuring infrastructure to choosing, customizing, and deploying models integrated with their business applications. Oracle has been helping enterprises of all sizes across industries for decades, from mission-critical applications to innovation that propels our customers ahead of their competitors.
At Oracle, we carefully thought through how an enterprise’s business processes could be enhanced with generative AI. We’ve created an end-to-end generative AI experience encompassing our entire stack. Built on our high-performing AI infrastructure, our AI offerings come with easy integration throughout the Oracle stack, from data made available for AI from database products such as Oracle Database, Oracle Autonomous Database, and MySQL HeatWave to SaaS applications such as ERP, HCM, and CX with embedded generative AI features. At Oracle, AI is designed to be a seamless experience—not piecemeal parts or tools that you have to assemble as part of a do-it-yourself project.
Not only is Oracle delivering an integrated, seamless AI experience, but we’re also delivering it where you need it. You can use Oracle Cloud Infrastructure (OCI) Generative AI in the Oracle Cloud and leverage all the advantages of the public cloud to scale solutions on demand, customize models, and create private model endpoints for business. With OCI Dedicated Region, Oracle will also deliver generative AI services in your data centers, so you can combine generative AI capabilities together with your on-premises data and applications.
As Dave Vellante, Chief Research Officer at Wikibon recently said, “Oracle is taking a full stack approach to enterprise generative AI. Oracle’s value starts at the top of the stack, not in silicon. By offering integrated generative AI across its Fusion SaaS applications, Oracle directly connects to customer business value. These apps are supported by autonomous databases with vector embeddings and run on high-performance infrastructure across OCI or on-prem with Dedicated Region. Together these offerings comprise a highly differentiated enterprise AI strategy, covering everything from out-of-the-box RAG to a broad range of fine-tuned models and AI infused throughout an integrated stack. Our research shows that 2023 was the year of AI experimentation. With capabilities such as this, our expectation is that 2024 will be the year of showing ROI in AI.”
Today, we’re excited to announce a broad range of innovations with new services and features, all designed to help you in your generative AI journey.
As we continue to deliver on our AI strategy, we’re announcing the general availability of the OCI Generative AI service, a managed service to seamlessly integrate LLMs into a wide range of enterprise use cases.
The OCI Generative AI service will now support Meta’s Llama 2 and Cohere’s models, together with a multilingual embeddings capability for over 100 languages. We’ve also added improvements to make it easier to work with LLMs with functionality such as LangChain integration, endpoint management, and content moderation.
OCI Generative AI will also include an improved GPU cluster management experience with multi-endpoint support to host clusters, the ability to handle more model requests by scaling clusters, and endpoint analytics.
The OCI Generative AI service now also offers flexible fine-tuning available for Cohere’s Command 52/6B models. As a result, enterprises can continue to feel confident that their AI precisely fits their specific business context.
With the OCI Generative AI service, customers can tackle a variety of use cases including:
Today, we’re also announcing the beta release of OCI Generative AI Agents service. Agents translate user queries into tasks that Generative AI components (search tool, document corpus, LLM, response generation, etc.) perform to answer the queries. The first in a series of OCI Generative AI Agents is a retrieval augmented generation (RAG) agent that complements the general knowledge of LLMs with internal data using OCI OpenSearch to provide contextually relevant answers. Users can now transparently access diverse enterprise data sets through natural language without the need for specialist skills or to know the data’s format or storage location
For example: when an end user asks an AI Agent to provide a summary of HR policies related to medical leaves the query signals the model to search a corpus of internal documents for the policies. The model then uses the RAG capabilities to extract relevant paragraphs and use them to generate a human language response to the end user, with hyperlinks to the relevant source documents. The AI Agent delivers this response to the end user in natural language. The user could continue to ask questions of the policies and the AI Agent would continue to answer questions within the context of the conversation, creating an accurate and human-like experience. In future iterations of the service, the end user will be able to prompt the AI Agent to take further action such as editing the original documents or navigating the HR system to make updates.
The initial beta release of OCI Generative AI Agents supports OpenSearch for accessing internal enterprise data, with upcoming releases expected to support a wider range of LLMs and provide access to Oracle Database 23c with AI Vector Search and MySQL HeatWave with Vector Store. This will enable users to build agents that automate their interactions with Oracle and third-party applications and direct the agent to take actions based on the query outcomes. Customers can sign up to join the beta program here.
OCI Data Science AI Quick Actions is a no-code feature of the OCI Data Science service that enables access to a wide range of open source LLMs, including options from Meta, Mistral AI, and more. Once generally available, this feature will provide wider access to the best of what the open-source community offers.
OCI Data Science Quick Actions provides access to curated models that users can fine tune, evaluate, and deploy with their data, but also encompasses a comprehensive ecosystem with user-friendly workflows, integrated telemetry and visualizations, and simplified execution processes.
Once generally available, AI Quick Actions provides:
Oracle Fusion Cloud Applications, Oracle NetSuite, and industry applications such as Oracle Health will have new generative AI capabilities, powered by the models in OCI Generative AI. Initial use cases focus on Summarization and Assisted Authoring, such as summarizing performance reviews, assisted authoring for job descriptions, assisted authoring for creating goals, writing knowledge articles, and generating relevant customer service emails. These AI capabilities in the hands of your workforce via the software environments that they use every day will enable higher levels of productivity and effectiveness in their core tasks and workflows.
Naturally, Oracle is also embedding generative AI capabilities into its database portfolio. Oracle Database 23c with AI Vector Search and MySQL HeatWave with Vector Store provide RAG capabilities so that users can combine internal data with LLMs to generate more accurate and contextually relevant answers to prompts.
In addition, with Autonomous Database Select AI, customers can leverage LLMs to use natural language queries rather than writing SQL when interacting with Oracle Autonomous Database. This enables customers to achieve faster AI adoption in their application development. Businesses and their customers can use the Select AI natural language interface combined with Oracle Database AI Vector Search to obtain quicker, more intuitive insights into their own data. For example, retailers can get customized inventory insights on demand and employees of regulated organizations can quickly query volumes of ordinances to check for compliance.
In addition to its generative AI focus, Oracle continues to improve our existing AI offerings. Our strategy is to provide enterprises with several options to help ensure your success. To that end, we’re offering several enhancements, including:
I mentioned earlier that we took a holistic approach to generative AI as we thought through the complete picture of what enterprises truly need to successfully implement generative AI. But beyond that, we have some core tenets to help ensure that our new offerings will be as valuable as possible for you:
We’re providing enterprise-focused models that are high performing and cost-effective, allowing for many uses cases and efficient fine tuning. We’re also increasingly adapting models to real-world enterprise scenarios, and performing specialized training on large language models with Oracle’s own proprietary knowledge and insights to make them better for business—all with access to best-in-class GPUs and high-performance cluster networking.
Oracle meets you where you are in your generative AI journey with a variety of embedded and managed services features across our infrastructure layer, platform services, and business applications. Working with AI may seem challenging—but it’s dramatically simpler if you’re working with a company that has created an entire cloud of integrated services from data to apps.
With Oracle, you can connect your AI models to your relevant data in real-time and retrieve contextualized responses. In addition, Oracle continues to help ensure that customer data is private and protected. We don’t share the data with any third-party model providers. For added privacy and security, we give you the option to perform dedicated deployments of LLMs on managed GPU infrastructure that isn’t shared with any other customers—and to deliver generative AI services to your data centers.
The Oracle AI platform uniquely offers a complete stack of high-performance infrastructure, built-in AI and ML with database and analytics products and AI services, as well as a generative AI service for application development. And this is just the beginning.
I invite you to try OCI Generative AI or any of our other Oracle AI products. If you’re new to Oracle Cloud Infrastructure, try Oracle Cloud Free Trial, a free 30-day trial with US$300 in credits. For more information, see the following resources:
Greg Pavlik is senior vice president where is responsible for product strategy, service delivery, and physical infrastructure for Oracle Cloud Infrastructure. His goal is to ensure Oracle has the most capable and performant cloud platform in the market.
Previous Post
Next Post