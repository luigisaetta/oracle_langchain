{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee731860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "# my OracleVectorStore for LangChain\n",
    "from oracle_vector_db_lc import OracleVectorStore\n",
    "\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "from config_private import COMPARTMENT_OCID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a6ba7-0d6d-478b-a6c6-dc27b73e635f",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8036f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# per il tracing\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "EMBED_MODEL = \"cohere.embed-multilingual-v3.0\"\n",
    "ENDPOINT = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "embed_model = OCIGenAIEmbeddings(\n",
    "    auth_type=\"API_KEY\",\n",
    "    model_id=EMBED_MODEL,\n",
    "    service_endpoint=ENDPOINT,\n",
    "    compartment_id=COMPARTMENT_OCID,\n",
    ")\n",
    "\n",
    "# build AI Vector Search Vector Store\n",
    "v_store = OracleVectorStore(\n",
    "    embedding=embed_model, collection_name=\"ORACLE_KNOWLEDGE\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b9baaf",
   "metadata": {},
   "source": [
    "#### Demo con Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e3a16e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 17:01:41,475 - INFO - HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-02-26 17:01:41,482 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 17:01:50,404 - INFO - HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "2024-02-26 17:01:50,541 - INFO - HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_darwin_arm64 \"HTTP/1.1 200 OK\"\n",
      "2024-02-26 17:02:10,502 - INFO - top_k: 5\n",
      "2024-02-26 17:02:10,503 - INFO - \n",
      "2024-02-26 17:02:10,504 - INFO -  2024-02-26 16:02:10.504617: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 17:02:13,046 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 5 ROWS ONLY\n",
      "2024-02-26 17:02:13,282 - INFO - Query duration: 0.5 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not create share link. Missing file: /Users/lsaetta/miniforge3/envs/langchain01/lib/python3.9/site-packages/gradio/frpc_darwin_arm64_v0.2. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.2\n",
      "3. Move the file to this location: /Users/lsaetta/miniforge3/envs/langchain01/lib/python3.9/site-packages/gradio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 17:03:12,264 - INFO - top_k: 5\n",
      "2024-02-26 17:03:12,266 - INFO - \n",
      "2024-02-26 17:03:12,267 - INFO -  2024-02-26 16:03:12.267701: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 17:03:12,765 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 5 ROWS ONLY\n",
      "2024-02-26 17:03:13,004 - INFO - Query duration: 0.4 sec.\n"
     ]
    }
   ],
   "source": [
    "# to format output\n",
    "def format_doc(doc, choice):\n",
    "    ref_name = doc.metadata[\"source\"]\n",
    "\n",
    "    if choice == \"Full\":\n",
    "        output = doc.page_content + \"\\n\\n\"\n",
    "        output += ref_name\n",
    "    else:\n",
    "        output = ref_name\n",
    "\n",
    "    # separatore\n",
    "    output += f\"\\n\\n--------------------------\\n\\n\"\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# costruisce il retrieve... consente di cambiare top_K\n",
    "def get_retriever(top_k):\n",
    "    retriever = v_store.as_retriever(search_kwargs={\"k\": top_k})\n",
    "\n",
    "    return retriever\n",
    "\n",
    "\n",
    "def retrieve(question, choice, top_k):\n",
    "    retriever = get_retriever(top_k)\n",
    "\n",
    "    # fa il retrieval\n",
    "    result_docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    # costruisce l'output\n",
    "    output = \"\"\n",
    "\n",
    "    for doc in result_docs:\n",
    "        output += format_doc(doc, choice)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    title=\"Semantic Search on OCI Knowledge\",\n",
    "    fn=retrieve,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, label=\"Question\"),\n",
    "        gr.Radio([\"Full\", \"Only ref\"], label=\"Select output type\", value=\"Full\"),\n",
    "        gr.Slider(minimum=2, maximum=10, step=1, label=\"TOP_K\", value=5),\n",
    "    ],\n",
    "    outputs=gr.Textbox(lines=10, interactive=False, label=\"Documents\"),\n",
    "    allow_flagging=\"never\",\n",
    "    analytics_enabled=False,\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3e5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53d8c0-082b-4d63-9a60-b254362e87c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd213814-13f6-491a-af98-aad96f246f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
