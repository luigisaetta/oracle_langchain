{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa887049-4203-4425-b598-a6c8a28d97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "# my OracleVectorStore for LangChain\n",
    "from oracle_vector_db_lc import OracleVectorStore\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from langchain_community.llms import OCIGenAI\n",
    "\n",
    "from utils import format_docs\n",
    "\n",
    "from config_private import COMPARTMENT_OCID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb043f4-6307-489f-9f82-c3c9e5a19495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per il tracing\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "EMBED_MODEL = \"cohere.embed-multilingual-v3.0\"\n",
    "GENAI_MODEL = \"cohere.command\"\n",
    "ENDPOINT = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "TOP_K = 4\n",
    "\n",
    "embed_model = OCIGenAIEmbeddings(\n",
    "    auth_type=\"API_KEY\",\n",
    "    model_id=EMBED_MODEL,\n",
    "    service_endpoint=ENDPOINT,\n",
    "    compartment_id=COMPARTMENT_OCID,\n",
    ")\n",
    "\n",
    "llm = OCIGenAI(\n",
    "    auth_type=\"API_KEY\",\n",
    "    model_id=GENAI_MODEL,\n",
    "    service_endpoint=ENDPOINT,\n",
    "    compartment_id=COMPARTMENT_OCID,\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "# the prompt. This is OK for Cohere\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# build AI Vector Search Vector Store\n",
    "v_store = OracleVectorStore(\n",
    "    embedding=embed_model, collection_name=\"ORACLE_KNOWLEDGE\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63738afd-4774-431c-9f22-ad9a45e3ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = v_store.as_retriever(search_kwargs={\"k\": TOP_K})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71974177-4cfc-4c35-aace-21b7286e54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LangChain LCEL language\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93286c8c-a61a-4f3f-a12a-4c0191febeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Oracle Strategy for Generative AI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19317100-e10a-4d6f-afc6-e082449fae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 18:07:25,132 - INFO - top_k: 4\n",
      "2024-02-26 18:07:25,133 - INFO - \n",
      "2024-02-26 18:07:26,049 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-26 18:07:26,267 - INFO - Query duration: 0.4 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Oracle Strategy for Generative AI?\n",
      "\n",
      " Oracle's strategy for generative AI centers around providing enterprises with an entire stack of integrated services, from data storage to applications. They aim to make working with AI simpler by providing enterprises with services that are tailored to their needs, with Oracle's value starting at the top of the stack rather than in silicon. Oracle plans to achieve this by offering generative AI across its Fusion SaaS applications, supported by autonomous databases with vector embeddings and run on high-performance infrastructure. This strategy is intended to deliver an integrated and seamless AI experience to enterprises, allowing them to scale solutions on demand, customize models, and create private model endpoints for business. \n",
      "\n",
      "Oracle also aims to provide enterprises with generative AI capabilities that are high performing and cost-effective, adapting models to real-world enterprise scenarios and training large language models with Oracle's proprietary knowledge and insights. \n",
      "\n",
      "Overall, Oracle's strategy for generative AI focuses on delivering value to enterprises by providing a comprehensive set of integrated services and solutions that enable businesses to seamlessly incorporate AI into their operations and achieve ROI. \n",
      "\n",
      "Would you like me to go into more detail about any of the aforementioned points? \n",
      "\n",
      "CPU times: user 134 ms, sys: 13.7 ms, total: 148 ms\n",
      "Wall time: 9.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(\"\")\n",
    "print(answer)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ef7258-657e-47d9-af8d-6700890be049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 18:08:02,878 - INFO - HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-02-26 18:08:02,886 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 18:08:08,544 - INFO - HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "2024-02-26 18:08:08,634 - INFO - HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_darwin_arm64 \"HTTP/1.1 200 OK\"\n",
      "2024-02-26 18:08:19,311 - INFO - top_k: 4\n",
      "2024-02-26 18:08:19,312 - INFO - \n",
      "2024-02-26 18:08:19,312 - INFO -  2024-02-26 17:08:19.312975: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 18:08:19,829 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-26 18:08:20,039 - INFO - Query duration: 0.4 sec.\n",
      "2024-02-26 18:08:20,042 - INFO -  2024-02-26 17:08:20.042215: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not create share link. Missing file: /Users/lsaetta/miniforge3/envs/langchain01/lib/python3.9/site-packages/gradio/frpc_darwin_arm64_v0.2. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.2\n",
      "3. Move the file to this location: /Users/lsaetta/miniforge3/envs/langchain01/lib/python3.9/site-packages/gradio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 18:09:03,010 - INFO - top_k: 4\n",
      "2024-02-26 18:09:03,011 - INFO - \n",
      "2024-02-26 18:09:03,013 - INFO -  2024-02-26 17:09:03.013738: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 18:09:03,481 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-26 18:09:03,700 - INFO - Query duration: 0.4 sec.\n",
      "2024-02-26 18:09:03,715 - INFO -  2024-02-26 17:09:03.715132: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n",
      "2024-02-26 18:09:55,009 - INFO - top_k: 4\n",
      "2024-02-26 18:09:55,010 - INFO - \n",
      "2024-02-26 18:09:55,012 - INFO -  2024-02-26 17:09:55.012309: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 18:09:55,993 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-26 18:09:56,206 - INFO - Query duration: 0.4 sec.\n",
      "2024-02-26 18:09:56,222 - INFO -  2024-02-26 17:09:56.222955: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n",
      "2024-02-26 18:15:12,275 - INFO - top_k: 4\n",
      "2024-02-26 18:15:12,276 - INFO - \n",
      "2024-02-26 18:15:12,278 - INFO -  2024-02-26 17:15:12.278636: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 18:15:54,992 - INFO -  2024-02-26 17:15:54.992366: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 18:15:56,141 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-26 18:15:56,360 - INFO - Query duration: 0.4 sec.\n",
      "2024-02-26 18:15:56,372 - INFO -  2024-02-26 17:15:56.372075: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n",
      "2024-02-26 18:16:23,321 - INFO -  2024-02-26 17:16:23.321541: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n",
      "2024-02-26 18:17:04,765 - INFO - top_k: 4\n",
      "2024-02-26 18:17:04,766 - INFO - \n",
      "2024-02-26 18:17:04,768 - INFO -  2024-02-26 17:17:04.768950: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 18:17:05,281 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-26 18:17:05,499 - INFO - Query duration: 0.4 sec.\n",
      "2024-02-26 18:17:05,513 - INFO -  2024-02-26 17:17:05.513243: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n",
      "2024-02-26 18:17:37,877 - INFO - top_k: 4\n",
      "2024-02-26 18:17:37,878 - INFO - \n",
      "2024-02-26 18:17:37,880 - INFO -  2024-02-26 17:17:37.880778: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-26 18:17:39,253 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-26 18:17:39,464 - INFO - Query duration: 0.4 sec.\n",
      "2024-02-26 18:17:39,479 - INFO -  2024-02-26 17:17:39.479253: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n"
     ]
    }
   ],
   "source": [
    "# to format output\n",
    "\n",
    "\n",
    "def answer(question):\n",
    "    answer = rag_chain.invoke(question)\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    title=\"Semantic Search on OCI Knowledge\",\n",
    "    fn=answer,\n",
    "    inputs=[gr.Textbox(lines=2, label=\"Question\")],\n",
    "    outputs=gr.Textbox(lines=10, interactive=False, label=\"Answer\"),\n",
    "    allow_flagging=\"never\",\n",
    "    analytics_enabled=False,\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16455e7-b306-4e82-991b-60d15653304b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
