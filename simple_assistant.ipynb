{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa887049-4203-4425-b598-a6c8a28d97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "# my OracleVectorStore for LangChain\n",
    "from oracle_vector_db_lc import OracleVectorStore\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from langchain_community.llms import OCIGenAI\n",
    "\n",
    "from utils import format_docs\n",
    "from config import EMBED_MODEL, GENAI_MODEL, ENDPOINT\n",
    "\n",
    "from config_private import COMPARTMENT_OCID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb043f4-6307-489f-9f82-c3c9e5a19495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per il tracing\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "TOP_K = 4\n",
    "\n",
    "embed_model = OCIGenAIEmbeddings(\n",
    "    auth_type=\"API_KEY\",\n",
    "    model_id=EMBED_MODEL,\n",
    "    service_endpoint=ENDPOINT,\n",
    "    compartment_id=COMPARTMENT_OCID,\n",
    ")\n",
    "\n",
    "llm = OCIGenAI(\n",
    "    auth_type=\"API_KEY\",\n",
    "    model_id=GENAI_MODEL,\n",
    "    service_endpoint=ENDPOINT,\n",
    "    compartment_id=COMPARTMENT_OCID,\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "# the prompt. This is OK for Cohere\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# build AI Vector Search Vector Store\n",
    "v_store = OracleVectorStore(\n",
    "    embedding=embed_model, collection_name=\"ORACLE_KNOWLEDGE\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63738afd-4774-431c-9f22-ad9a45e3ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = v_store.as_retriever(search_kwargs={\"k\": TOP_K})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71974177-4cfc-4c35-aace-21b7286e54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LangChain LCEL language\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93286c8c-a61a-4f3f-a12a-4c0191febeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Oracle Strategy for Generative AI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19317100-e10a-4d6f-afc6-e082449fae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 16:51:39,949 - INFO - top_k: 4\n",
      "2024-02-27 16:51:39,950 - INFO - \n",
      "2024-02-27 16:51:42,436 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-27 16:51:42,652 - INFO - Query duration: 0.4 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Oracle Strategy for Generative AI?\n",
      "\n",
      " Oracle's strategy for generative AI centers around providing enterprises with high-performing models at a low cost. They aim to empower businesses with access to best-in-class GPUs and networking, specialized training with their own insights, and seamless integration across their entire cloud of services, from data to applications. Oracle seeks to simplify the use of AI for businesses and improve ROI by offering enterprises an entire stack of integrated services, from out-of-the-box models to AI-infused SaaS applications supported by autonomous databases. \n",
      "\n",
      " oracle also provides its OCI Generative AI service, which can be used on-demand and scaled using the public cloud. Alternatively, they can deliver their services via dedicated regions within client data centers. \n",
      "\n",
      "Through these methods, Oracle aims to differentiate its enterprise AI strategy while accommodating businesses regardless of their stage in their AI journey. \n",
      "\n",
      "Would you like help with another question regarding the context you provided? \n",
      "\n",
      "CPU times: user 149 ms, sys: 15.8 ms, total: 164 ms\n",
      "Wall time: 9.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(\"\")\n",
    "print(answer)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ef7258-657e-47d9-af8d-6700890be049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 16:51:55,305 - INFO - HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-02-27 16:51:55,314 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 16:51:56,865 - INFO - HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "2024-02-27 16:51:57,100 - INFO - HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_darwin_arm64 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not create share link. Missing file: /Users/lsaetta/miniforge3/envs/langchain01/lib/python3.9/site-packages/gradio/frpc_darwin_arm64_v0.2. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.2\n",
      "3. Move the file to this location: /Users/lsaetta/miniforge3/envs/langchain01/lib/python3.9/site-packages/gradio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 16:52:28,791 - INFO - top_k: 4\n",
      "2024-02-27 16:52:28,792 - INFO - \n",
      "2024-02-27 16:52:28,794 - INFO -  2024-02-27 15:52:28.794570: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-27 16:52:30,634 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-27 16:52:30,846 - INFO - Query duration: 0.4 sec.\n",
      "2024-02-27 16:52:30,867 - INFO -  2024-02-27 15:52:30.866994: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n",
      "2024-02-27 16:53:29,836 - INFO - top_k: 4\n",
      "2024-02-27 16:53:29,837 - INFO - \n",
      "2024-02-27 16:53:29,838 - INFO -  2024-02-27 15:53:29.838933: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-27 16:53:30,397 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-27 16:53:30,615 - INFO - Query duration: 0.5 sec.\n",
      "2024-02-27 16:53:30,632 - INFO -  2024-02-27 15:53:30.632280: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n",
      "2024-02-27 16:54:37,563 - INFO - top_k: 4\n",
      "2024-02-27 16:54:37,564 - INFO - \n",
      "2024-02-27 16:54:37,565 - INFO -  2024-02-27 15:54:37.565603: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\n",
      "2024-02-27 16:54:39,547 - INFO - select: select C.id, C.CHUNK, C.REF, \n",
      "                            ROUND(VECTOR_DISTANCE(C.VEC, :1, DOT), 3) as d \n",
      "                            from ORACLE_KNOWLEDGE C\n",
      "                            order by d\n",
      "                            FETCH FIRST 4 ROWS ONLY\n",
      "2024-02-27 16:54:39,764 - INFO - Query duration: 0.4 sec.\n",
      "2024-02-27 16:54:39,771 - INFO -  2024-02-27 15:54:39.771906: Request: POST https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\n"
     ]
    }
   ],
   "source": [
    "def answer(question):\n",
    "    answer = rag_chain.invoke(question)\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    title=\"Semantic Search on OCI Knowledge\",\n",
    "    fn=answer,\n",
    "    inputs=[gr.Textbox(lines=2, label=\"Question\")],\n",
    "    outputs=gr.Textbox(lines=10, interactive=False, label=\"Answer\"),\n",
    "    allow_flagging=\"never\",\n",
    "    analytics_enabled=False,\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16455e7-b306-4e82-991b-60d15653304b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
